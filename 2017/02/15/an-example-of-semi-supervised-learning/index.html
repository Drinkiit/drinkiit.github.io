<!doctype html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Series Estimator,Nonparametric Statistics," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="1. Semi-Supervised Learning (SSL)Semi-supervised learning uses both labeled and unlabeled data.[4] That is the learner has both labeled training data ${(\textbf{x}_i,z_i) : i=1,2,\dots,n }$ and unlabe">
<meta property="og:type" content="article">
<meta property="og:title" content="Nonparametric Series Estimator as An Example of Semi-Supervised Learning">
<meta property="og:url" content="http://yoursite.com/2017/02/15/an-example-of-semi-supervised-learning/index.html">
<meta property="og:site_name" content="Yida's Blog">
<meta property="og:description" content="1. Semi-Supervised Learning (SSL)Semi-supervised learning uses both labeled and unlabeled data.[4] That is the learner has both labeled training data ${(\textbf{x}_i,z_i) : i=1,2,\dots,n }$ and unlabe">
<meta property="og:image" content="http://yoursite.com/2017/02/15/an-example-of-semi-supervised-learning/seriesApproximation.png">
<meta property="og:updated_time" content="2017-03-15T01:08:37.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Nonparametric Series Estimator as An Example of Semi-Supervised Learning">
<meta name="twitter:description" content="1. Semi-Supervised Learning (SSL)Semi-supervised learning uses both labeled and unlabeled data.[4] That is the learner has both labeled training data ${(\textbf{x}_i,z_i) : i=1,2,\dots,n }$ and unlabe">
<meta name="twitter:image" content="http://yoursite.com/2017/02/15/an-example-of-semi-supervised-learning/seriesApproximation.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"always"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/02/15/an-example-of-semi-supervised-learning/"/>





  <title> Nonparametric Series Estimator as An Example of Semi-Supervised Learning | Yida's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-91889551-1', 'auto');
  ga('send', 'pageview');
</script>











  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Yida's Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
    
      <p class="site-subtitle"></p>
    
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

<link rel="apple-touch-icon" href="/apple-touch-icon.png">

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/02/15/an-example-of-semi-supervised-learning/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Yida Yin">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/smiling_man.jpg">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="Yida's Blog">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="Yida's Blog" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Nonparametric Series Estimator as An Example of Semi-Supervised Learning
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-02-15T13:15:51-06:00">
                2017-02-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/02/15/an-example-of-semi-supervised-learning/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2017/02/15/an-example-of-semi-supervised-learning/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="1-Semi-Supervised-Learning-SSL"><a href="#1-Semi-Supervised-Learning-SSL" class="headerlink" title="1. Semi-Supervised Learning (SSL)"></a>1. Semi-Supervised Learning (SSL)</h3><p>Semi-supervised learning uses both labeled and unlabeled data.[4] That is the learner has both labeled training data ${(\textbf{x}_i,z_i) : i=1,2,\dots,n }$ and unlabeled training data ${\textbf{x}_i : i=n+1,\dots,n+p }$, where $\textbf{x}_i$ is a multidimensional vector and $z_i$ is a scalar.  The goal is to learn a predictor that predicts $z$ given the new test data $\textbf{x}$. Or in other words, we want to find a mapping $\varphi: \textbf{X} \rightarrow \textbf{z}$ that maps the input space $\textbf{X}$ to the value space $\textbf{z}$. The problem is unlabeled data ${\textbf{x}_i : i=n+1,\dots,n+p }$ by itself does not carry any information on the mapping $\varphi: \textbf{X} \rightarrow \textbf{z}$, so how can it help us learn a better predictor? </p>
<a id="more"></a>
<p>Self-training, starting in the 1960s, might be the oldest approach to semi-supervised learning. Generative models introduced by Vladimir Vapnik in the 1970s are also very popular approach to semi-supervised learning. But these methods cannot give a very detailed answer to the question above. Here I would like to introduce an example of the semi-supervised learning method, which is a nonparametric series approach proposed by Izbicki and Lee. This series framework can be naturally extended to semi-supervised learning (Zhu and Goldberg 2009). And they also provided the converge rate with and without the unlabeled data.</p>
<h3 id="2-Nonparametric-Spectral-Series-Estimator-for-Conditional-Density"><a href="#2-Nonparametric-Spectral-Series-Estimator-for-Conditional-Density" class="headerlink" title="2. Nonparametric Spectral Series Estimator for Conditional Density"></a>2. Nonparametric Spectral Series Estimator for Conditional Density</h3><p>Rafael IZBICKI and Ann B. LEE[2] propose a new nonparametric series estimator to estimate the condition density of $z$ given $\textbf{x}$. Their method follows the following steps: first use the eigenfunctions of an special defined integral operator as the basis of $\textbf{x}$. We can see that these eigenfunctions are orthonormal with respect to the data distribution $P(\textbf{x})$. Then choose a suitable orthonormal basis on the domain of $z$. After that they define a specral series to be the estimate of the conditional density $f(z|\textbf{x})$.</p>
<p>In the first step, the estimator of the spectral basis on the domain of $\textbf{x}$ depends only on $\textbf{x}$ and has nothing to do with $z$. So in this case, <strong><em>By including the unlabeled data in the first step, we can better estimate the eigenfunctions which form the basis on the domain of $\textbf{x}$, and hence the conditional density.</em></strong></p>
<p>Section 3 describes the triditional series estimators in both univariate and multivariate case. In section 4, we talk about this spectral series method. </p>
<h3 id="3-Introduction-to-Series-Estimator-3-Chapter2-3-and-6"><a href="#3-Introduction-to-Series-Estimator-3-Chapter2-3-and-6" class="headerlink" title="3. Introduction to Series Estimator[3 Chapter2, 3 and 6]"></a>3. Introduction to Series Estimator[3 Chapter2, 3 and 6]</h3><h4 id="3-1-Orthonormal-Basis-Univariate-Case-3-Chapter2"><a href="#3-1-Orthonormal-Basis-Univariate-Case-3-Chapter2" class="headerlink" title="3.1 Orthonormal Basis (Univariate Case) [3 Chapter2]"></a>3.1 Orthonormal Basis (Univariate Case) [3 Chapter2]</h4><p>For a given function $f(x)$, we can describe it via a series expansion. Suppose the domain of $f(x)$ is $[0,1]$. Then<br>$$f(x)=\sum_{j=0}^{\infty}\theta_j\varphi_j(x), \ \textrm{where}\ \theta_j = \int_0^1 f(x)\varphi_j(x) dx$$<br>Here the functions $\varphi_j(x)$ are called $orthonormal\ functions$, and the $\theta_j$ are called the $Fourier$ coefficients. A system of functions is called $orthonormal$ if the integral $\int_0^1 \varphi_s(x)\varphi_j(x) dx = 0$ for all $s \ne j$ and $\int_0^1 (\varphi_j(x))^2 dx = 1$ for all $j$.<br>However, describe a function via an infinite orthogonal series expansion workable. Instead, a truncated (finite) orthonormal series<br>$$f(x)=\sum_{j=0}^{J}\theta_j\varphi_j(x)$$<br>is used to approximate $f$. The integer parameter $J$ is called the cutoff.<br>For example, it is very easy to show that the ‘Cosine system’ is an orthonormal system on $[0, 1]$. The elements in Cosine system are:<br>$$\varphi_0(x)=1 \ \textrm{and}\ \varphi_j=\sqrt{2} \cos(\pi jx) \ \ \textrm{for} \ \ j=1,2,\dots$$<br><img src="/2017/02/15/an-example-of-semi-supervised-learning/seriesApproximation.png"><br>This plot comes from [3, P22]. It shows the approximation of eight corner functions (solid lines) by cosine series: dotted, short-dashed, and long-dashed lines correspond to cutoffs $J = 3$, $J = 5$, and $J = 10$, respectively.</p>
<h4 id="3-2-Tensor-Product-Multivariate-Case-3-Chapter6"><a href="#3-2-Tensor-Product-Multivariate-Case-3-Chapter6" class="headerlink" title="3.2 Tensor Product (Multivariate Case)  [3 Chapter6]"></a>3.2 Tensor Product (Multivariate Case)  [3 Chapter6]</h4><p>The approximation methods discussed above can be extended to multivariate case using the so-called ‘tensor–product basis’ which makes the problem of series approximation of multivariate functions similar to the univariate case. In this post, we only focus on the case of bivariate functions. Multivariate functions can be treated with this method similarly. </p>
<p>Denote by $L(A \times B)$ the space of square integrable bivariate functions $f(x,y)$ such that $\int_A \int_B f^2\big(x, y\big)dxdy &lt; \infty$.  </p>
<p>Let ${ \phi_n(x), n=0,1,2,\dots }$ and ${ \psi_m(y), n=0,1,2,\dots }$ be two bases in the one-dimensional spaces $L_2(A)$ and $L_2(B)$. Then products of elements from these two bases,  </p>
<p>$${ \varphi_{nm}(x, y) =  \phi_n(x)  \psi_m(y),\ n,m=0,1,\dots }$$<br>constitute a basis in $L_2(A \times B)$. This basis is called the tensor-product basis. </p>
<p>For example, the cosine tensor-product basis in $L_2([0,1]^2)$ has the elements:    </p>
<p>$$<br>\varphi_{00}(x, y)=1, \varphi_{01}(x,y)=\sqrt2\cos(\pi y), \varphi_{02}(x,y)=\sqrt2\cos(2\pi y), \dots   \nonumber \\\<br>\varphi_{10}(x, y)=\sqrt2\cos(\pi x), \varphi_{11}(x,y)=2\cos(\pi x)\cos(\pi y), \dots<br>$$</p>
<p>And a corresponding partial sum with cutoffs $J_1$ and $J_2$ relative to the variables $x$ and $y$ is:<br>$$f_{J_1, J_2}(x,y)=\sum_{j_1=0}^{J_1} \sum_{j_2=0}^{J_2} \theta_{j_1j_2} \varphi_{j_1j_2} (x,y)$$<br>where the Fourier coefficients $\theta_{j_1j_2}$ are defined by the formula:<br>$$\theta_{j_1j_2} = \int_0^1 \int_0^1 f(x,y) \varphi_{j_1j_2} dxdy$$</p>
<h4 id="3-3-Density-Estimation-3-Chapter-3"><a href="#3-3-Density-Estimation-3-Chapter-3" class="headerlink" title="3.3 Density Estimation [3; Chapter 3]"></a>3.3 Density Estimation [3; Chapter 3]</h4><p>If $f$ is the probability density, the choice of an estimate for Fourier coefficients is straightforward. Indeed, the coefficient $\theta_j$ may be written as<br>$$\theta_j = E[I_{X\in[0,1]} \varphi_j(x)]$$<br>And the natural estimate of the theoretical mean is the sample mean,<br>$$\hat{\theta_j}=n^{-1}\sum_{l=1}^nI_{X_l\in[0,1]} \varphi_j(X_l)$$</p>
<h3 id="4-Spectral-Series-Estimator-TODO"><a href="#4-Spectral-Series-Estimator-TODO" class="headerlink" title="4. Spectral Series Estimator (TODO)"></a>4. Spectral Series Estimator (TODO)</h3><h4 id="4-1-Introduction"><a href="#4-1-Introduction" class="headerlink" title="4.1 Introduction"></a>4.1 Introduction</h4><h4 id="4-2-Algorithm"><a href="#4-2-Algorithm" class="headerlink" title="4.2 Algorithm"></a>4.2 Algorithm</h4><h4 id="4-3-Discuss"><a href="#4-3-Discuss" class="headerlink" title="4.3 Discuss"></a>4.3 Discuss</h4><p>[1] <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning" target="_blank" rel="external">https://en.wikipedia.org/wiki/Semi-supervised_learning</a></p>
<p>[2] Izbicki, Rafael, and Ann B. Lee. “Nonparametric Conditional Density Estimation in a High-Dimensional Regression Setting.” Journal of Computational and Graphical Statistics,(just accepted) (2015).</p>
<p>[3] Efromovich S. Nonparametric curve estimation: methods, theory, and applications[M]. Springer Science &amp; Business Media, 2008.</p>
<p>[4] Zhu, Xiaojin. “Semi-supervised learning.” Encyclopedia of Machine Learning. Springer US, 2011. 892-897.</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Series-Estimator/" rel="tag"># Series Estimator</a>
          
            <a href="/tags/Nonparametric-Statistics/" rel="tag"># Nonparametric Statistics</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/02/13/The-Lighthouse-Problem/" rel="next" title="The Lighthouse Problem | and why sample mean is not a good estimator">
                <i class="fa fa-chevron-left"></i> The Lighthouse Problem | and why sample mean is not a good estimator
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/03/18/isotonic-regression/" rel="prev" title="Isotonic Regression">
                Isotonic Regression <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/smiling_man.jpg"
               alt="Yida Yin" />
          <p class="site-author-name" itemprop="name">Yida Yin</p>
          <p class="site-description motion-element" itemprop="description">There are three kinds of lies: lies, damned lies and statistics</p>
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="http://yidayin.me/" target="_blank" title="AboutMe">
                  
                    <i class="fa fa-fw fa-hand-spock-o"></i>
                  
                  AboutMe
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Semi-Supervised-Learning-SSL"><span class="nav-number">1.</span> <span class="nav-text">1. Semi-Supervised Learning (SSL)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Nonparametric-Spectral-Series-Estimator-for-Conditional-Density"><span class="nav-number">2.</span> <span class="nav-text">2. Nonparametric Spectral Series Estimator for Conditional Density</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Introduction-to-Series-Estimator-3-Chapter2-3-and-6"><span class="nav-number">3.</span> <span class="nav-text">3. Introduction to Series Estimator[3 Chapter2, 3 and 6]</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-Orthonormal-Basis-Univariate-Case-3-Chapter2"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 Orthonormal Basis (Univariate Case) [3 Chapter2]</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-Tensor-Product-Multivariate-Case-3-Chapter6"><span class="nav-number">3.2.</span> <span class="nav-text">3.2 Tensor Product (Multivariate Case)  [3 Chapter6]</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-Density-Estimation-3-Chapter-3"><span class="nav-number">3.3.</span> <span class="nav-text">3.3 Density Estimation [3; Chapter 3]</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Spectral-Series-Estimator-TODO"><span class="nav-number">4.</span> <span class="nav-text">4. Spectral Series Estimator (TODO)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-Introduction"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 Introduction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-Algorithm"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 Algorithm</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-Discuss"><span class="nav-number">4.3.</span> <span class="nav-text">4.3 Discuss</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yida Yin</span>
</div>



        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  

    <script type="text/javascript">
      var disqus_shortname = 'drinkiit';
      var disqus_identifier = '2017/02/15/an-example-of-semi-supervised-learning/';

      var disqus_title = "Nonparametric Series Estimator as An Example of Semi-Supervised Learning";


      function run_disqus_script(disqus_script) {
        var dsq = document.createElement('script');
        dsq.type = 'text/javascript';
        dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      }

      run_disqus_script('count.js');

      
        var disqus_config = function () {
            this.page.url = disqus_url;
            this.page.identifier = disqus_identifier;
            this.page.title = disqus_title;
        };
        run_disqus_script('embed.js');
      

    </script>
  










  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  


</body>
</html>
